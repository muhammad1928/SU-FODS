{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Regression and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will preprocess the dataset and perform some basic regression and classification tasks. The learning outcome of this part is to know how one can pre-process a real-world dataset and perform a supervised learning task, and to understand some of the fundamental mechanisms behind these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student information\n",
    "Please provide your information for automatic grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUD_SUID = 'aabb0000'\n",
    "STUD_NAME = 'Aaaa Bbbb'\n",
    "STUD_EMAIL = 'aaaa.bbbb@dsv.su.se'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Grading: \n",
    "\n",
    "Pass/Fail.\n",
    "\n",
    "To Pass this HW you need to provide a complete and correct solution, where one minor mistake is allowed. However, if your solution has more minor mistakes or lacks parts entirely or has one or more major mistakes, then you receive a Fail grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLINE: \n",
    "\n",
    "Data pre-processing, regression task and classification task\n",
    "\n",
    "1. Reading the files\n",
    "2. Missing Values\n",
    "3. Imputing categorical variables\n",
    "4. Imputing numerical variables\n",
    "5. Classification with Decision Tree, single split\n",
    "6. Classification with Decision Tree, Cross validation\n",
    "7. Interpretation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important instructions:\n",
    "\n",
    "Each function you make will be considered during the grading, so it is important to strictly follow input and output instructions stated in the skeleton code.\n",
    "\n",
    "You must not delete any of the given cells or change the structure of the cells or change the instructions in the cells or add cells (unless completely necessary, add a comment on why you added a cell) as they will help in grading the assignment. Should you contravene this provision, you will fail the assignment, and no feedback will be given on the part after the contravention.\n",
    "\n",
    "Some variable names are already given and have random values or empty arrays assigned on them. In this case you should only change the assignments on the variables but keep the names as given.\n",
    "\n",
    "When you are finished with implementing all the tasks, **clear all outputs, run all cells again** (make sure there is no error) and submit!\n",
    "\n",
    "Make sure that the results and figures asked are visible for us to grade.\n",
    "\n",
    "Make sure not to modify the files in the \"data\" folder in your submission, and not to change the folder structure or the files location, or your submission will not obtain a passing grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure consistent results, make sure that every operation in which you can use a random seed has it set to 8. If your process is correct, but the results are wrong due to the seed being wrong, it will be considered a major mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the libraries that you will need throughout the assignment\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "RSEED = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *1.* Reading the files\n",
    "\n",
    "### `Task: Read the datasets using pandas. Use the files called cleveland.data and switzerland.data that you have downloaded in this archive.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contain information about adult patients from the US and from Switzerland. You can find more information in the heart-disease.names file in the 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From the folder 'data', read the files cleveland.data and switzerland.data into the dataframes cleveland and test, respectively.\n",
    "# # Make sure to add the names of the variables to both dataframes.\n",
    "\n",
    " \n",
    "# columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'] # you can find the column names in the file 'data/heart-disease.names'.\n",
    "# # Select the correct column names for the dataset, as described in the file.\n",
    "# print(columns)\n",
    "\n",
    "# cleveland1 = pd.read_csv(\"../data/cleveland.data\", names=columns )\n",
    "# cleveland = pd.DataFrame(cleveland1)  \n",
    "# print(cleveland)\n",
    "# test1 = pd.read_csv(\"../data/switzerland.data\", names=columns)\n",
    "# test = pd.DataFrame(test1)       \n",
    "# print(test)\n",
    "\n",
    "columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "           'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
    "\n",
    "cleveland = pd.read_csv(\"../data/cleveland.data\", names=columns )\n",
    "\n",
    "test = pd.read_csv('../data/switzerland.data', names=columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# to fix in cleveland   : age, set limit.  \n",
    "# to fix in test        :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  num  \n",
       "0    3.0  0.0  6.0    0  \n",
       "1    2.0  3.0  3.0    2  \n",
       "2    2.0  2.0  7.0    1  \n",
       "3    3.0  0.0  3.0    0  \n",
       "4    1.0  0.0  3.0    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not delete this!\n",
    "cleveland.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps  chol fbs restecg  thalach  exang  oldpeak slope  \\\n",
       "0  32.0  1.0  1.0      95.0   0.0   ?       0    127.0    0.0      0.7     1   \n",
       "1  34.0  1.0  4.0     115.0   0.0   ?       ?    154.0    0.0      0.2     1   \n",
       "2  36.0  1.0  4.0     110.0   0.0   ?       0    125.0    1.0      1.0     2   \n",
       "3  38.0  0.0  4.0     105.0   0.0   ?       0    166.0    0.0      2.8     1   \n",
       "4  38.0  0.0  4.0     110.0   0.0   0       0    156.0    0.0      0.0     2   \n",
       "\n",
       "  ca thal  num  \n",
       "0  ?    ?  1.0  \n",
       "1  ?    ?  1.0  \n",
       "2  ?    6  1.0  \n",
       "3  ?    ?  2.0  \n",
       "4  ?    3  1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not delete this!\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.270627</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.296578</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    60.270627    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std     77.296578    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min      0.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max    999.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope         num  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.937294  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    1.228536  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    2.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    4.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to see information about the dataset, \n",
    "# uncomment:\n",
    "cleveland.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>122.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>82.409836</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>3.683761</td>\n",
       "      <td>129.957265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.299145</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>1.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>170.211621</td>\n",
       "      <td>0.280782</td>\n",
       "      <td>0.702822</td>\n",
       "      <td>22.423200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.759921</td>\n",
       "      <td>0.498007</td>\n",
       "      <td>1.056061</td>\n",
       "      <td>1.011866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps   chol     thalach  \\\n",
       "count  122.000000  117.000000  117.000000  117.000000  117.0  117.000000   \n",
       "mean    82.409836    0.914530    3.683761  129.957265    0.0  122.299145   \n",
       "std    170.211621    0.280782    0.702822   22.423200    0.0   25.759921   \n",
       "min      0.000000    0.000000    1.000000   80.000000    0.0   60.000000   \n",
       "25%     48.500000    1.000000    4.000000  115.000000    0.0  105.000000   \n",
       "50%     56.000000    1.000000    4.000000  125.000000    0.0  121.000000   \n",
       "75%     61.000000    1.000000    4.000000  145.000000    0.0  141.000000   \n",
       "max    999.000000    1.000000    4.000000  200.000000    0.0  182.000000   \n",
       "\n",
       "            exang     oldpeak         num  \n",
       "count  117.000000  117.000000  117.000000  \n",
       "mean     0.435897    0.653846    1.769231  \n",
       "std      0.498007    1.056061    1.011866  \n",
       "min      0.000000   -2.600000    0.000000  \n",
       "25%      0.000000    0.000000    1.000000  \n",
       "50%      0.000000    0.300000    2.000000  \n",
       "75%      1.000000    1.500000    3.000000  \n",
       "max      1.000000    3.700000    4.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to see information about the dataset, uncomment:\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *2.* Missing values\n",
    "\n",
    "### `Task: Produce a plot with two subplots, each showing a bar plot of the 'missing' values (either encoded as NaN, or encoded with values that should not be in the dataset) for each feature for the two dataframes. The plot must have a name, and the bars must be named using the feature names.`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           2\n",
      "sex           0\n",
      "cp            0\n",
      "trestbps      0\n",
      "chol          0\n",
      "fbs           0\n",
      "restecg       0\n",
      "thalach       0\n",
      "exang         0\n",
      "oldpeak       0\n",
      "slope         0\n",
      "ca            4\n",
      "thal          7\n",
      "num         212\n",
      "dtype: int64\n",
      "age           4\n",
      "sex           5\n",
      "cp            5\n",
      "trestbps      5\n",
      "chol        122\n",
      "fbs          76\n",
      "restecg       6\n",
      "thalach       5\n",
      "exang         5\n",
      "oldpeak       5\n",
      "slope        16\n",
      "ca          117\n",
      "thal         56\n",
      "num          44\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create 1 figure with a set of 2 subplots. Each axes should contain a figure as described below: \n",
    "\n",
    "# subplot 1: A barplot with the missing valies for each attribute in the dataset 'cleveland'\n",
    "# subplot 2: A barplot with the missing valies for each attribute in the dataset 'test'\n",
    "# Subplot 1: Cleveland dataset\n",
    "\n",
    "\n",
    "\n",
    "# Convert non-numeric values to NaN for all columns\n",
    "for col in cleveland.columns:\n",
    "    cleveland[col] = pd.to_numeric(cleveland[col], errors='coerce')\n",
    "\n",
    "# filter age above 120 to nan\n",
    "cleveland.loc[cleveland['age'] > 120, 'age'] = np.nan\n",
    "# filter num values which are not 1 or 0 to nan\n",
    "cleveland.loc[~cleveland['num'].isin([1, 2]), 'num'] = np.nan\n",
    "# filter and convert chol values 0 to nan\n",
    "cleveland.loc[cleveland['chol'] == 0, 'chol'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Convert non-numeric values to NaN for all columns\n",
    "for col in test.columns:\n",
    "    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "# filter age above 120 to nan\n",
    "test.loc[test['age'] > 120, 'age'] = np.nan\n",
    "# filter num values which are not 1 or 0 to nan\n",
    "test.loc[~test['num'].isin([1, 2]), 'num'] = np.nan\n",
    "# filter and convert chol values 0 to nan\n",
    "test.loc[test['chol'] == 0, 'chol'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Create a figure and axes for the subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Subplot 1: Cleveland dataset\n",
    "cleveland_missing = cleveland.isnull().sum()\n",
    "cleveland_missing.plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Missing Values in Cleveland Dataset')\n",
    "axes[0].set_ylabel('Number of Missing Values')\n",
    "axes[0].set_xlabel('Attributes')\n",
    "\n",
    "# Subplot 2: Test dataset (Switzerland)\n",
    "test_missing = test.isnull().sum()\n",
    "test_missing.plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Missing Values in Switzerland Dataset')\n",
    "axes[1].set_ylabel('Number of Missing Values')\n",
    "axes[1].set_xlabel('Attributes')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(cleveland.isnull().sum())         # count nan values\n",
    "\n",
    "print(test.isnull().sum())              # count nan values\n",
    "\n",
    "\n",
    "\n",
    "# to fix in cleveland   : age, set limit.  num,\n",
    "# to fix in test        : age, chol, num, ca, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *3.* Imputing categorical variables\n",
    "\n",
    "In the file 'data/heart-disease.names' you can find, together with the names of the columns, a description of their contents.\n",
    "\n",
    "Determine which columns are categorical, and set their type to object.\n",
    "\n",
    "Determine which columns are numerical, and set their type accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         float64\n",
      "sex          object\n",
      "cp           object\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs          object\n",
      "restecg      object\n",
      "thalach     float64\n",
      "exang        object\n",
      "oldpeak     float64\n",
      "slope        object\n",
      "ca           object\n",
      "thal         object\n",
      "num          object\n",
      "dtype: object\n",
      "age         float64\n",
      "sex          object\n",
      "cp           object\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs          object\n",
      "restecg      object\n",
      "thalach     float64\n",
      "exang        object\n",
      "oldpeak     float64\n",
      "slope        object\n",
      "ca           object\n",
      "thal         object\n",
      "num          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3 age: age in years  # float \n",
    "# 4 sex: sex (1 = male; 0 = female) # float \n",
    "# 9 cp: chest pain type # float \n",
    "#         -- Value 1: typical angina\n",
    "#         -- Value 2: atypical angina\n",
    "#         -- Value 3: non-anginal pain\n",
    "#         -- Value 4: asymptomatic\n",
    "# 10 trestbps: resting blood pressure (in mm Hg on admission to the  # float \n",
    "#         hospital)\n",
    "# 12 chol: serum cholestoral in mg/dl float \n",
    "# 16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "# 19 restecg: resting electrocardiographic results\n",
    "#         -- Value 0: normal\n",
    "#         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n",
    "#                     elevation or depression of > 0.05 mV)\n",
    "#         -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "#                     by Estes' criteria\n",
    "# 32 thalach: maximum heart rate achieved\n",
    "# 38 exang: exercise induced angina (1 = yes; 0 = no)\n",
    "# 40 oldpeak = ST depression induced by exercise relative to rest\n",
    "# 41 slope: the slope of the peak exercise ST segment\n",
    "#         -- Value 1: upsloping\n",
    "#         -- Value 2: flat\n",
    "#         -- Value 3: downsloping\n",
    "# 44 ca: number of major vessels (0-3) colored by flourosopy\n",
    "# 51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "# 58 num: diagnosis of heart disease (angiographic disease status)\n",
    "#         -- Value 0: < 50% diameter narrowing\n",
    "#         -- Value 1: > 50% diameter narrowing\n",
    "#         (in any major vessel: attributes 59 through 68 are vessels)\n",
    "\n",
    "\n",
    "\n",
    "# Define categorical and numerical columns based on the provided description\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'num']\n",
    "numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "# Convert categorical columns to object type\n",
    "for col in categorical_cols:\n",
    "    cleveland[col] = cleveland[col].astype('object')\n",
    "    test[col] = test[col].astype('object')\n",
    "\n",
    "# Ensure numerical columns are numeric (already handled in previous code)\n",
    "for col in numerical_cols:\n",
    "    cleveland[col] = pd.to_numeric(cleveland[col], errors='coerce')\n",
    "    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "# Print the data types of each column to verify the changes (optional)\n",
    "print(cleveland.dtypes)\n",
    "print(test.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Split the cleveland dataframe in a train and a validation set. `\n",
    "\n",
    "The train set must be called train, the the validation set must be called val. The size of the validation set must be 30% of the total size of the cleveland dataframe. Use shuffle=True and stratify=True. Make sure that both train and val are dataframes, and that the columns have the correct names. Reset the indexes of all four the dataframes, using drop=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y, where X contains the features and y contains the target variable.\n",
    "\n",
    "\n",
    "\n",
    "X_cleveland = cleveland.drop('num', axis=1)\n",
    "y_cleveland = cleveland['num']\n",
    "\n",
    "# Before splitting, remove rows with NaN values in the target variable\n",
    "cleveland_filtered = cleveland.dropna(subset=['num'])  # Drop rows with NaN in 'num'\n",
    "X_cleveland = cleveland_filtered.drop('num', axis=1)  # Update X_cleveland\n",
    "y_cleveland = cleveland_filtered['num']  # Update y_cleveland\n",
    "\n",
    "# Split the Cleveland dataset into training and validation sets\n",
    "train, val, _, _ = train_test_split(\n",
    "    X_cleveland, y_cleveland, test_size=0.3, random_state=RSEED, shuffle=True, stratify=y_cleveland\n",
    ")\n",
    "\n",
    "# Convert the splits back to dataframes\n",
    "train = pd.DataFrame(train, columns=X_cleveland.columns).reset_index(drop=True)\n",
    "val = pd.DataFrame(val, columns=X_cleveland.columns).reset_index(drop=True)\n",
    "\n",
    "X_test = test.drop('num', axis=1).reset_index(drop=True)\n",
    "y_test = test['num'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train, val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs restecg  thalach exang  oldpeak slope  \\\n",
       "0  45.0  1.0  1.0     110.0  264.0  0.0     0.0    132.0   0.0      1.2   2.0   \n",
       "1  60.0  1.0  4.0     130.0  253.0  0.0     0.0    144.0   1.0      1.4   1.0   \n",
       "2  47.0  1.0  4.0     110.0  275.0  0.0     2.0    118.0   1.0      1.0   2.0   \n",
       "3  60.0  1.0  4.0     125.0  258.0  0.0     2.0    141.0   1.0      2.8   2.0   \n",
       "4  61.0  0.0  4.0     130.0  330.0  0.0     2.0    169.0   0.0      0.0   1.0   \n",
       "\n",
       "    ca thal  \n",
       "0  0.0  7.0  \n",
       "1  1.0  7.0  \n",
       "2  1.0  3.0  \n",
       "3  1.0  7.0  \n",
       "4  0.0  3.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs restecg  thalach exang  oldpeak slope  \\\n",
       "0  54.0  1.0  4.0     124.0  266.0  0.0     2.0    109.0   1.0      2.2   2.0   \n",
       "1  65.0  1.0  4.0     110.0  248.0  0.0     2.0    158.0   0.0      0.6   1.0   \n",
       "2  56.0  1.0  3.0     130.0  256.0  1.0     2.0    142.0   1.0      0.6   2.0   \n",
       "3  49.0  1.0  3.0     118.0  149.0  0.0     2.0    126.0   0.0      0.8   1.0   \n",
       "4   0.0  1.0  4.0     112.0  290.0  0.0     2.0    153.0   0.0      0.0   1.0   \n",
       "\n",
       "    ca thal  \n",
       "0  1.0  7.0  \n",
       "1  2.0  6.0  \n",
       "2  1.0  6.0  \n",
       "3  3.0  3.0  \n",
       "4  1.0  3.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "X_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the classification task easier, transform the target variable into a binary variable.\n",
    "# If the target variable is 0, it should remain 0. If the target variable is different from 0, it should be transformed into 1.\n",
    "\n",
    "\n",
    "y_train = np.where(y_train == 0, 0, 1)\n",
    "y_val = np.where(y_val == 0, 0, 1)\n",
    "y_test = np.where(y_test == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_set_from_franco = pd.read_csv('../../../testing_data/train.csv')\\nval_set_from_franco = pd.read_csv('../../../testing_data/val.csv')\\n\\nassert train.equals(train_set_from_franco), 'train set is not correct'\\nassert val.equals(val_set_from_franco), 'validation set is not correct'\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "\n",
    "'''\n",
    "train_set_from_franco = pd.read_csv('../../../testing_data/train.csv')\n",
    "val_set_from_franco = pd.read_csv('../../../testing_data/val.csv')\n",
    "\n",
    "assert train.equals(train_set_from_franco), 'train set is not correct'\n",
    "assert val.equals(val_set_from_franco), 'validation set is not correct'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: impute the missing values in the categorical columns. Use a KNNImputer from sklearn for the imputation process. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a subset of the train dataset with only the categorical columns. Call this subset train_cat.\n",
    "# 2. Create a subset of the val dataset with only the categorical columns. Call this subset val_cat.\n",
    "# 3. Create a subset of the test dataset with only the categorical columns. Call this subset test_cat\n",
    "# 4. Impute the three datasets using a KNN imputer with k=5 and weights set to distance\n",
    "# 5. Save the results in train_imputed_knn, val_imputed_knn, and test_imputed_knn.\n",
    "# 6. Make sure to add the column names to the resulting dataframes. DO NOT SKIP THIS STEP.\n",
    "# The new values might have new values that are not in the original dataset.\n",
    "# Approximate them to the nearest value in the original dataset, for each column.\n",
    "# To do so, you can store the original values of each column in a dictionary or a list.\n",
    "# if a new value is equidistant from two original values, choose the largest one.\n",
    "# (Example: if the original values are [1, 3] and the new value is 2, it will become 3)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Remove 'num' from categorical_cols as it's not in the train, val, or X_test DataFrames\n",
    "categorical_cols_for_imputation = [col for col in categorical_cols if col != 'num'] \n",
    "\n",
    "# Create subsets of categorical columns\n",
    "train_cat = train[categorical_cols_for_imputation]\n",
    "val_cat = val[categorical_cols_for_imputation]\n",
    "test_cat = X_test[categorical_cols_for_imputation]\n",
    "\n",
    "# Initialize KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5) # You can adjust n_neighbors\n",
    "\n",
    "# Fit and transform the categorical columns of the training set\n",
    "train_cat_imputed = imputer.fit_transform(train_cat)\n",
    "\n",
    "# Transform the validation and test sets using the same imputer\n",
    "val_cat_imputed = imputer.transform(val_cat)\n",
    "test_cat_imputed = imputer.transform(test_cat)\n",
    "\n",
    "# Convert back to DataFrames (optional, but recommended)\n",
    "train_cat_imputed = pd.DataFrame(train_cat_imputed, columns=train_cat.columns)\n",
    "val_cat_imputed = pd.DataFrame(val_cat_imputed, columns=val_cat.columns)\n",
    "test_cat_imputed = pd.DataFrame(test_cat_imputed, columns=test_cat.columns)\n",
    "# Define find_nearest function before it's used\n",
    "def find_nearest(value, array):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "# Initialize KNNImputer with weights='distance'\n",
    "imputer_knn = KNNImputer(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Fit and transform the numerical columns of the training set\n",
    "train_num_imputed = imputer_knn.fit_transform(train[numerical_cols])\n",
    "# Transform the validation and test sets using the same imputer\n",
    "val_num_imputed = imputer_knn.transform(val[numerical_cols])\n",
    "test_num_imputed = imputer_knn.transform(X_test[numerical_cols])\n",
    "\n",
    "# Convert back to DataFrames and add column names\n",
    "train_num_imputed = pd.DataFrame(train_num_imputed, columns=numerical_cols)\n",
    "val_num_imputed = pd.DataFrame(val_num_imputed, columns=numerical_cols)\n",
    "test_num_imputed = pd.DataFrame(test_num_imputed, columns=numerical_cols)\n",
    "\n",
    "# Combine imputed numerical and categorical data\n",
    "train_imputed_knn = pd.concat([train_num_imputed, train_cat_imputed], axis=1)\n",
    "val_imputed_knn = pd.concat([val_num_imputed, val_cat_imputed], axis=1)\n",
    "test_imputed_knn = pd.concat([test_num_imputed, test_cat_imputed], axis=1)\n",
    "\n",
    "# Approximate to nearest values in the original dataset\n",
    "for col in train_imputed_knn.columns:\n",
    "    if col in categorical_cols:\n",
    "        # Find unique values in the original dataset\n",
    "        unique_vals = np.unique(cleveland[col].dropna())\n",
    "        # Round imputed values to the nearest unique value\n",
    "        train_imputed_knn[col] = np.round(train_imputed_knn[col]).astype(int)\n",
    "        train_imputed_knn[col] = train_imputed_knn[col].apply(lambda x: find_nearest(x, unique_vals))\n",
    "        val_imputed_knn[col] = np.round(val_imputed_knn[col]).astype(int)\n",
    "        val_imputed_knn[col] = val_imputed_knn[col].apply(lambda x: find_nearest(x, unique_vals))\n",
    "        test_imputed_knn[col] = np.round(test_imputed_knn[col]).astype(int)\n",
    "        test_imputed_knn[col] = test_imputed_knn[col].apply(lambda x: find_nearest(x, unique_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_imp_knn_franco = pd.read_csv('../../../testing_data/train_imp_knn.csv')\\nval_imp_knn_franco = pd.read_csv('../../../testing_data/val_imp_knn.csv')\\ntest_imp_knn_franco = pd.read_csv('../../../testing_data/test_imp_knn.csv')\\n\\nassert train_imputed_knn.equals(train_imp_knn_franco), 'train imputed knn is not correct'\\nassert val_imputed_knn.equals(val_imp_knn_franco), 'val imputed knn is not correct'\\nassert test_imputed_knn.equals(test_imp_knn_franco), 'test imputed knn is not correct'\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "'''\n",
    "train_imp_knn_franco = pd.read_csv('../../../testing_data/train_imp_knn.csv')\n",
    "val_imp_knn_franco = pd.read_csv('../../../testing_data/val_imp_knn.csv')\n",
    "test_imp_knn_franco = pd.read_csv('../../../testing_data/test_imp_knn.csv')\n",
    "\n",
    "assert train_imputed_knn.equals(train_imp_knn_franco), 'train imputed knn is not correct'\n",
    "assert val_imputed_knn.equals(val_imp_knn_franco), 'val imputed knn is not correct'\n",
    "assert test_imputed_knn.equals(test_imp_knn_franco), 'test imputed knn is not correct'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4.* Imputing numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: impute the missing values in the numerical columns. Use a Lasso Regression from sklearn for the imputation process. `\n",
    "If more than one column contains missing values, proceed in increasing order: the lowest number of missing values first, then the second lowest, then the third ...\n",
    "\n",
    "Exclude the columns with missing values when fitting your regressor: only train on columns without missing values. After a column has been imputed, it can be used to fit the regressor in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_imputed_lasso: (63, 5)\n",
      "Shape of val_imputed_lasso: (28, 5)\n",
      "Shape of test_imputed_lasso: (122, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_18100\\2282748580.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_num_missing.loc[train_num_missing[col].isnull(), col] = predicted_values\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a subset of the train dataset with only the numerical columns. Call this subset train_num.\n",
    "# 2. Create a subset of the val dataset with only the numerical columns. Call this subset val_num.\n",
    "# 3. Create a subset of the test dataset with only the numerical columns. Call this subset test_num.\n",
    "# 4a. Create a subset of train_num containing the rows with missing values. Call this subset train_num_missing.\n",
    "# 4b. Create a subset of train_num containing the rows without missing values. Call this subset train_num_not_missing.\n",
    "# 5a. Create a subset of val_num containing the rows with missing values. Call this subset val_num_missing.\n",
    "# 5b. Create a subset of val_num containing the rows without missing values. Call this subset val_num_not_missing.\n",
    "# 6a. Create a subset of test_num containing the rows with missing values. Call this subset test_num_missing.\n",
    "# 6b. Create a subset of test_num containing the rows without missing values. Call this subset test_num_not_missing.\n",
    "# 7. Using a Lasso regression, impute the missing values in train_num_missing, val_num_missing, and test_num_missing.\n",
    "# On what should the Lasso regression be trained?\n",
    "# 8. Repeat steps 1-7 until all the missing values are imputed.\n",
    "# 9. Save the results in train_num_imputed_lasso, val_num_imputed_lasso, and test_num_imputed_lasso.\n",
    "# 10. Concatenate the imputed subsets with the subsets that did not contain missing values.\n",
    "# 11. Save the resulting datasets in train_imputed_lasso, val_imputed_lasso, and test_imputed_lasso.\n",
    "# IMPORTANT: The order of the rows should be the same as in the original datasets.\n",
    "\n",
    "\n",
    "# 1. Create subsets with numerical columns\n",
    "train_num = train[numerical_cols]\n",
    "val_num = val[numerical_cols]\n",
    "test_num = X_test[numerical_cols]\n",
    "\n",
    "# 4. Create subsets of train_num with and without missing values\n",
    "train_num_missing = train_num[train_num.isnull().any(axis=1)]\n",
    "train_num_not_missing = train_num.dropna()\n",
    "\n",
    "# 5. Create subsets of val_num with and without missing values\n",
    "val_num_missing = val_num[val_num.isnull().any(axis=1)]\n",
    "val_num_not_missing = val_num.dropna()\n",
    "\n",
    "# 6. Create subsets of test_num with and without missing values\n",
    "test_num_missing = test_num[test_num.isnull().any(axis=1)]\n",
    "test_num_not_missing = test_num.dropna()\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# 7. Impute missing values using Lasso regression\n",
    "# Fit Lasso regression model on the training data without missing values\n",
    "lasso_model = Lasso()  # Initialize Lasso model\n",
    "\n",
    "# Here you should implement the actual Lasso training\n",
    "# For demonstration, let's assume we're trying to impute the first column of train_num_missing.\n",
    "# You may want to replace `target_column` with the actual column you want to predict.\n",
    "\n",
    "target_column = train_num_missing.columns[0]  # Placeholder for the target column to impute\n",
    "X_train = train_num_not_missing.drop(columns=target_column)\n",
    "y_train = train_num_not_missing[target_column]\n",
    "\n",
    "# Fit the Lasso model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Now we will use the Lasso model to predict the missing values in train_num_missing\n",
    "for col in train_num_missing.columns:\n",
    "    if train_num_missing[col].isnull().any():\n",
    "        # Predict missing values using the fitted model\n",
    "        X_missing = train_num_missing.drop(columns=col).dropna()  # Exclude the target column and rows with NaN\n",
    "        predicted_values = lasso_model.predict(X_missing)\n",
    "        train_num_missing.loc[train_num_missing[col].isnull(), col] = predicted_values\n",
    "\n",
    "# Placeholder for the actual Lasso imputation - replace with your implementation\n",
    "train_num_imputed_lasso = train_num_missing.copy()\n",
    "val_num_imputed_lasso = val_num_missing.copy()\n",
    "test_num_imputed_lasso = test_num_missing.copy()\n",
    "\n",
    "# Example: Fill NaN with 0 (Replace with your actual Lasso imputation)\n",
    "train_num_imputed_lasso.fillna(0, inplace=True)\n",
    "val_num_imputed_lasso.fillna(0, inplace=True)\n",
    "test_num_imputed_lasso.fillna(0, inplace=True)\n",
    "\n",
    "# Concatenate the imputed subsets with the subsets that did not contain missing values\n",
    "train_imputed_lasso = pd.concat([train_num_imputed_lasso, train_num_not_missing], axis=0)\n",
    "val_imputed_lasso = pd.concat([val_num_imputed_lasso, val_num_not_missing], axis=0)\n",
    "test_imputed_lasso = pd.concat([test_num_imputed_lasso, test_num_not_missing], axis=0)\n",
    "\n",
    "# Restore original order\n",
    "train_imputed_lasso = train_imputed_lasso.sort_index()\n",
    "val_imputed_lasso = val_imputed_lasso.sort_index()\n",
    "test_imputed_lasso = test_imputed_lasso.sort_index()\n",
    "\n",
    "# Print shapes of the final imputed DataFrames\n",
    "print(\"Shape of train_imputed_lasso:\", train_imputed_lasso.shape)\n",
    "print(\"Shape of val_imputed_lasso:\", val_imputed_lasso.shape)\n",
    "print(\"Shape of test_imputed_lasso:\", test_imputed_lasso.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_imp_lasso_franco = pd.read_csv('../../../testing_data/train_imp_lasso.csv')\\nval_imp_lasso_franco = pd.read_csv('../../../testing_data/val_imp_lasso.csv')\\ntest_imp_lasso_franco = pd.read_csv('../../../testing_data/test_imp_lasso.csv')\\n\\nassert train_imputed_lasso.equals(train_imp_lasso_franco), 'train imputed lasso is not correct'\\nassert val_imputed_lasso.equals(val_imp_lasso_franco), 'val imputed lasso is not correct'\\nassert test_imputed_lasso.equals(test_imp_lasso_franco), 'test imputed lasso is not correct'\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "'''\n",
    "train_imp_lasso_franco = pd.read_csv('../../../testing_data/train_imp_lasso.csv')\n",
    "val_imp_lasso_franco = pd.read_csv('../../../testing_data/val_imp_lasso.csv')\n",
    "test_imp_lasso_franco = pd.read_csv('../../../testing_data/test_imp_lasso.csv')\n",
    "\n",
    "assert train_imputed_lasso.equals(train_imp_lasso_franco), 'train imputed lasso is not correct'\n",
    "assert val_imputed_lasso.equals(val_imp_lasso_franco), 'val imputed lasso is not correct'\n",
    "assert test_imputed_lasso.equals(test_imp_lasso_franco), 'test imputed lasso is not correct'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *5.* Classification with Decision Tree, using a single split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the train_imputed_knn and train_imputed_lasso datasets. Call the resulting dataset X_train_imputed.\n",
    "# Merge the val_imputed_knn and val_imputed_lasso datasets. Call the resulting dataset X_val_imputed.\n",
    "# Merge the test_imputed_knn and test_imputed_lasso datasets. Call the resulting dataset X_test_imputed.\n",
    "\n",
    "X_train_imputed = pd.concat([train_imputed_knn, train_imputed_lasso], axis=1)\n",
    "X_val_imputed = pd.concat([val_imputed_knn, val_imputed_lasso], axis=1)\n",
    "X_test_imputed = pd.concat([test_imputed_knn, test_imputed_lasso], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Train a set of Decision Trees, using different hyperparameters. Use the best performing Decision Tree to predict the class for the test set. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_imputed: (63, 18)\n",
      "Length of y_train: 62\n",
      "Index of X_train_imputed: RangeIndex(start=0, stop=63, step=1)\n",
      "Index of y_train: Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "       55, 56, 57, 58, 59, 60, 61, 62],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_imputed:\", X_train_imputed.shape)\n",
    "print(\"Length of y_train:\", len(y_train))\n",
    "# Check the index of both datasets\n",
    "print(\"Index of X_train_imputed:\", X_train_imputed.index)\n",
    "print(\"Index of y_train:\", y_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=62 does not match number of samples=63",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m clf \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# - Fit the model.\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_imputed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure you replace these with your actual training data\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# - Predict the target variable for the validation set.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_val_imputed)  \u001b[38;5;66;03m# Ensure you replace this with your actual validation data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:355\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    352\u001b[0m max_leaf_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_leaf_nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_leaf_nodes\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m!=\u001b[39m n_samples:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m does not match number of samples=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(y), n_samples)\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=62 does not match number of samples=63"
     ]
    }
   ],
   "source": [
    "# 1. Create a dictionary to contain the hyperparameters. The dictionary should contain the following:\n",
    "# - criterion: 'gini' and 'entropy'\n",
    "# - max_depth: 3, 5, and 7\n",
    "# - min_samples_split: 2, 5, and 10\n",
    "# 2. Create a dictionary called performance to store the hyperparameter combinations and the corresponding performance of the model.\n",
    "# 3. Create a ParameterGrid object with the hyperparameters from the dictionary.\n",
    "# 4. Create a for loop to iterate over the combinations of hyperparameters.\n",
    "# 5. In each iteration\n",
    "# - Create a DecisionTreeClassifier with the hyperparameters for that iteration.\n",
    "# - Fit the model.\n",
    "# - Predict the target variable for the validation set.\n",
    "# - Calculate the F1 score of the model.\n",
    "# - Add the hyperparameters and the F1 score to the performance dictionary.\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "# 1. Create a dictionary to contain the hyperparameters.\n",
    "hyperparameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# 2. Create a dictionary called performance to store the hyperparameter combinations and the corresponding performance of the model.\n",
    "performance = {}\n",
    "\n",
    "# 3. Create a ParameterGrid object with the hyperparameters from the dictionary.\n",
    "param_grid = ParameterGrid(hyperparameters)\n",
    "\n",
    "start = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "for params in param_grid:\n",
    "    # 5. In each iteration\n",
    "    # - Create a DecisionTreeClassifier with the hyperparameters for that iteration.\n",
    "    clf = DecisionTreeClassifier(**params)\n",
    "\n",
    "    # - Fit the model.\n",
    "    clf.fit(X_train_imputed, y_train)  # Ensure you replace these with your actual training data\n",
    "\n",
    "    # - Predict the target variable for the validation set.\n",
    "    y_pred = clf.predict(X_val_imputed)  # Ensure you replace this with your actual validation data\n",
    "\n",
    "    # - Calculate the F1 score of the model.\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')  # Ensure y_val is defined\n",
    "\n",
    "    # - Add the hyperparameters and the F1 score to the performance dictionary.\n",
    "    performance[tuple(params.items())] = f1\n",
    "\n",
    "end = time.time()  # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "print(\"Performance results:\", performance)\n",
    "print('Time elapsed to run the hyperparameter tuning with a single split: ', end - start)  # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best performing hyperparameters\n",
    "best_hyperparameters = None # change this\n",
    "\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train and validation datasets. Call the resulting datasets X and y.\n",
    "X = pd.DataFrame()  # change this\n",
    "y = pd.DataFrame()  # change this\n",
    "\n",
    "# Create a DecisionTreeClassifier with the best hyperparameters.\n",
    "# Fit the model on the X and y datasets.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "# Predict the target variable for the test dataset.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "# Calculate the F1 score of the model on the test dataset. Call the variable f1_test_single_split.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "f1_test_single_split = None # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test_single_split # DO NOT DELETE/CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *6.* Classification with Decision Tree using Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Train a cross-validation object, then train a decision tree using cross-validation and different hyperparameters. Use the best performing Decision Tree to predict the class for the test set. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to run the hyperparameter tuning with Cross Validation:  0.0012249946594238281\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the same hyperparameters from the previous task.\n",
    "# 2. Create a StratifiedKFold object with 5 splits, use shuffle=True.\n",
    "# 3. Create a dictionary called performance_CV to store the hyperparameter combinations and the corresponding performance of the model.\n",
    "# 3. Create a ParameterGrid object with the usual hyperparameters.\n",
    "# 4. Create a for loop to iterate over the folds of the StratifiedKFold.\n",
    "# 5. For each fold, create a for loop to iterate over the combinations of hyperparameters.\n",
    "# 6. In each iteration\n",
    "# - Create a DecisionTreeClassifier with the hyperparameters for that iteration.\n",
    "# - Fit the model.\n",
    "# - Predict the target variable for the validation fold.\n",
    "# - Calculate the F1 score of the model.\n",
    "# - Add the hyperparameters and the F1 score to the performance dictionary. Each hyperparameter combination may have multiple F1 scores.\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = [[5,6], [10,11], [15,16], [20,21], [25,26], [30,31], [35,36], [40,41], [45,46], [50,51]]    # Delete this line\n",
    "y = [0,1,0,1,0,1,0,1,0,1]                                                                       # Delete this line\n",
    "\n",
    "X = pd.DataFrame(X)                                                                             # Delete this line\n",
    "y = pd.DataFrame(y)                                                                             # Delete this line\n",
    "\n",
    "\n",
    "# DO NOT FORGET TO DELETE THE PREVIOUS LINES. They are only to make the empty assignment run without errors,\n",
    "# but they will destroy the data you need.\n",
    "\n",
    "\n",
    "CV = StratifiedKFold() # change this\n",
    "\n",
    "hyperparameters = None # change this\n",
    "# add missing steps here\n",
    "\n",
    "start_CV = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(CV.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    for number in range(1, 11): # change this\n",
    "        # Add the missing steps here.\n",
    "        pass # remove this line\n",
    "\n",
    "end_CV = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "print('Time elapsed to run the hyperparameter tuning with Cross Validation: ', end_CV - start_CV) # DO NOT CHANGE/DELETE THIS LINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best performing hyperparameters, which are the ones with the highest average F1 score\n",
    "best_hyperparameters_CV = None # change this\n",
    "\n",
    "best_hyperparameters_CV # DO NOT DELETE/CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DecisionTreeClassifier with the best hyperparameters.\n",
    "# Fit the model on the X and y datasets.\n",
    "# Call the fitted model final_tree.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "# Predict the target variable for the test dataset.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "# Calculate the F1 score of the model on the test dataset. Call the variable f1_test_CV.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "f1_test_CV = None # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test_CV # DO NOT DELETE/CHANGE THIS LINE \n",
    " \n",
    "  \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *7.* Interpretation of the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Look at the times elapsed to train the Decision Tree using the single split and the CV strategies. Is there a difference? Explain the difference or the lack of difference in 50 words or less. `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your explanation here. Delete this text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Plot final_tree, and explain which feature or combination of features is the most relevant for that model, in 50 words or less. `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find instructions on how to plot a decision tree at [this link](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot your tree here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your explanation here. Delete this text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
