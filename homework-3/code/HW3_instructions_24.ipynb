{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Regression and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will preprocess the dataset and perform some basic regression and classification tasks. The learning outcome of this part is to know how one can pre-process a real-world dataset and perform a supervised learning task, and to understand some of the fundamental mechanisms behind these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student information\n",
    "Please provide your information for automatic grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUD_SUID = 'aabb0000'\n",
    "STUD_NAME = 'Aaaa Bbbb'\n",
    "STUD_EMAIL = 'aaaa.bbbb@dsv.su.se'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Grading: \n",
    "\n",
    "Pass/Fail.\n",
    "\n",
    "To Pass this HW you need to provide a complete and correct solution, where one minor mistake is allowed. However, if your solution has more minor mistakes or lacks parts entirely or has one or more major mistakes, then you receive a Fail grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLINE: \n",
    "\n",
    "Data pre-processing, regression task and classification task\n",
    "\n",
    "1. Reading the files\n",
    "2. Missing Values\n",
    "3. Imputing categorical variables\n",
    "4. Imputing numerical variables\n",
    "5. Classification with Decision Tree, single split\n",
    "6. Classification with Decision Tree, Cross validation\n",
    "7. Interpretation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important instructions:\n",
    "\n",
    "Each function you make will be considered during the grading, so it is important to strictly follow input and output instructions stated in the skeleton code.\n",
    "\n",
    "You must not delete any of the given cells or change the structure of the cells or change the instructions in the cells or add cells (unless completely necessary, add a comment on why you added a cell) as they will help in grading the assignment. Should you contravene this provision, you will fail the assignment, and no feedback will be given on the part after the contravention.\n",
    "\n",
    "Some variable names are already given and have random values or empty arrays assigned on them. In this case you should only change the assignments on the variables but keep the names as given.\n",
    "\n",
    "When you are finished with implementing all the tasks, **clear all outputs, run all cells again** (make sure there is no error) and submit!\n",
    "\n",
    "Make sure that the results and figures asked are visible for us to grade.\n",
    "\n",
    "Make sure not to modify the files in the \"data\" folder in your submission, and not to change the folder structure or the files location, or your submission will not obtain a passing grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure consistent results, make sure that every operation in which you can use a random seed has it set to 8. If your process is correct, but the results are wrong due to the seed being wrong, it will be considered a major mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the libraries that you will need throughout the assignment\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "RSEED = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *1.* Reading the files\n",
    "\n",
    "### `Task: Read the datasets using pandas. Use the files called cleveland.data and switzerland.data that you have downloaded in this archive.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contain information about adult patients from the US and from Switzerland. You can find more information in the heart-disease.names file in the 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From the folder 'data', read the files cleveland.data and switzerland.data into the dataframes cleveland and test, respectively.\n",
    "# # Make sure to add the names of the variables to both dataframes.\n",
    "\n",
    " \n",
    "# columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'] # you can find the column names in the file 'data/heart-disease.names'.\n",
    "# # Select the correct column names for the dataset, as described in the file.\n",
    "# print(columns)\n",
    "\n",
    "# cleveland1 = pd.read_csv(\"../data/cleveland.data\", names=columns )\n",
    "# cleveland = pd.DataFrame(cleveland1)  \n",
    "# print(cleveland)\n",
    "# test1 = pd.read_csv(\"../data/switzerland.data\", names=columns)\n",
    "# test = pd.DataFrame(test1)       \n",
    "# print(test)\n",
    "\n",
    "columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "           'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
    "\n",
    "cleveland = pd.read_csv(\"../data/cleveland.data\", names=columns )\n",
    "\n",
    "test = pd.read_csv('../data/switzerland.data', names=columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# to fix in cleveland   : age, set limit.  \n",
    "# to fix in test        :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  num  \n",
       "0    3.0  0.0  6.0    0  \n",
       "1    2.0  3.0  3.0    2  \n",
       "2    2.0  2.0  7.0    1  \n",
       "3    3.0  0.0  3.0    0  \n",
       "4    1.0  0.0  3.0    0  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not delete this!\n",
    "cleveland.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps  chol fbs restecg  thalach  exang  oldpeak slope  \\\n",
       "0  32.0  1.0  1.0      95.0   0.0   ?       0    127.0    0.0      0.7     1   \n",
       "1  34.0  1.0  4.0     115.0   0.0   ?       ?    154.0    0.0      0.2     1   \n",
       "2  36.0  1.0  4.0     110.0   0.0   ?       0    125.0    1.0      1.0     2   \n",
       "3  38.0  0.0  4.0     105.0   0.0   ?       0    166.0    0.0      2.8     1   \n",
       "4  38.0  0.0  4.0     110.0   0.0   0       0    156.0    0.0      0.0     2   \n",
       "\n",
       "  ca thal  num  \n",
       "0  ?    ?  1.0  \n",
       "1  ?    ?  1.0  \n",
       "2  ?    6  1.0  \n",
       "3  ?    ?  2.0  \n",
       "4  ?    3  1.0  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not delete this!\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.270627</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.296578</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    60.270627    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std     77.296578    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min      0.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max    999.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope         num  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.937294  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    1.228536  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    2.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    4.000000  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to see information about the dataset, \n",
    "# uncomment:\n",
    "cleveland.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>122.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>82.409836</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>3.683761</td>\n",
       "      <td>129.957265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.299145</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>1.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>170.211621</td>\n",
       "      <td>0.280782</td>\n",
       "      <td>0.702822</td>\n",
       "      <td>22.423200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.759921</td>\n",
       "      <td>0.498007</td>\n",
       "      <td>1.056061</td>\n",
       "      <td>1.011866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps   chol     thalach  \\\n",
       "count  122.000000  117.000000  117.000000  117.000000  117.0  117.000000   \n",
       "mean    82.409836    0.914530    3.683761  129.957265    0.0  122.299145   \n",
       "std    170.211621    0.280782    0.702822   22.423200    0.0   25.759921   \n",
       "min      0.000000    0.000000    1.000000   80.000000    0.0   60.000000   \n",
       "25%     48.500000    1.000000    4.000000  115.000000    0.0  105.000000   \n",
       "50%     56.000000    1.000000    4.000000  125.000000    0.0  121.000000   \n",
       "75%     61.000000    1.000000    4.000000  145.000000    0.0  141.000000   \n",
       "max    999.000000    1.000000    4.000000  200.000000    0.0  182.000000   \n",
       "\n",
       "            exang     oldpeak         num  \n",
       "count  117.000000  117.000000  117.000000  \n",
       "mean     0.435897    0.653846    1.769231  \n",
       "std      0.498007    1.056061    1.011866  \n",
       "min      0.000000   -2.600000    0.000000  \n",
       "25%      0.000000    0.000000    1.000000  \n",
       "50%      0.000000    0.300000    2.000000  \n",
       "75%      1.000000    1.500000    3.000000  \n",
       "max      1.000000    3.700000    4.000000  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to see information about the dataset, uncomment:\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *2.* Missing values\n",
    "\n",
    "### `Task: Produce a plot with two subplots, each showing a bar plot of the 'missing' values (either encoded as NaN, or encoded with values that should not be in the dataset) for each feature for the two dataframes. The plot must have a name, and the bars must be named using the feature names.`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         2\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        7\n",
      "num         0\n",
      "dtype: int64\n",
      "age           4\n",
      "sex           5\n",
      "cp            5\n",
      "trestbps      5\n",
      "chol        122\n",
      "fbs          76\n",
      "restecg       6\n",
      "thalach       5\n",
      "exang         5\n",
      "oldpeak       5\n",
      "slope        16\n",
      "ca          117\n",
      "thal         56\n",
      "num           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create 1 figure with a set of 2 subplots. Each axes should contain a figure as described below: \n",
    "\n",
    "# subplot 1: A barplot with the missing valies for each attribute in the dataset 'cleveland'\n",
    "# subplot 2: A barplot with the missing valies for each attribute in the dataset 'test'\n",
    "# Subplot 1: Cleveland dataset\n",
    "\n",
    "\n",
    "\n",
    "# Convert non-numeric values to NaN for all columns\n",
    "for col in cleveland.columns:\n",
    "    cleveland[col] = pd.to_numeric(cleveland[col], errors='coerce')\n",
    "\n",
    "# filter age above 120 to nan\n",
    "cleveland.loc[cleveland['age'] > 120, 'age'] = np.nan\n",
    "# filter num values which are not 1 or 0 to 1\n",
    "cleveland.loc[~cleveland['num'].isin([1, 2]), 'num'] = 1\n",
    "# filter and convert chol values 0 to nan\n",
    "cleveland.loc[cleveland['chol'] == 0, 'chol'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Convert non-numeric values to NaN for all columns\n",
    "for col in test.columns:\n",
    "    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "# filter age above 120 to nan\n",
    "test.loc[test['age'] > 120, 'age'] = np.nan\n",
    "# filter num values which are not 1 or 0 to 1\n",
    "test.loc[~test['num'].isin([0, 1]), 'num'] = 1\n",
    "# filter and convert chol values 0 to nan\n",
    "test.loc[test['chol'] == 0, 'chol'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Create a figure and axes for the subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Subplot 1: Cleveland dataset\n",
    "cleveland_missing = cleveland.isnull().sum()\n",
    "cleveland_missing.plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Missing Values in Cleveland Dataset')\n",
    "axes[0].set_ylabel('Number of Missing Values')\n",
    "axes[0].set_xlabel('Attributes')\n",
    "\n",
    "# Subplot 2: Test dataset (Switzerland)\n",
    "test_missing = test.isnull().sum()\n",
    "test_missing.plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Missing Values in Switzerland Dataset')\n",
    "axes[1].set_ylabel('Number of Missing Values')\n",
    "axes[1].set_xlabel('Attributes')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(cleveland.isnull().sum())         # count nan values\n",
    "\n",
    "print(test.isnull().sum())              # count nan values\n",
    "\n",
    "\n",
    "\n",
    "# to fix in cleveland   : age, set limit.  num,\n",
    "# to fix in test        : age, chol, num, ca, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *3.* Imputing categorical variables\n",
    "\n",
    "In the file 'data/heart-disease.names' you can find, together with the names of the columns, a description of their contents.\n",
    "\n",
    "Determine which columns are categorical, and set their type to object.\n",
    "\n",
    "Determine which columns are numerical, and set their type accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         float64\n",
      "sex          object\n",
      "cp           object\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs          object\n",
      "restecg      object\n",
      "thalach     float64\n",
      "exang        object\n",
      "oldpeak     float64\n",
      "slope        object\n",
      "ca           object\n",
      "thal         object\n",
      "num          object\n",
      "dtype: object\n",
      "age         float64\n",
      "sex          object\n",
      "cp           object\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs          object\n",
      "restecg      object\n",
      "thalach     float64\n",
      "exang        object\n",
      "oldpeak     float64\n",
      "slope        object\n",
      "ca           object\n",
      "thal         object\n",
      "num          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3 age: age in years  # float \n",
    "# 4 sex: sex (1 = male; 0 = female) # float \n",
    "# 9 cp: chest pain type # float \n",
    "#         -- Value 1: typical angina\n",
    "#         -- Value 2: atypical angina\n",
    "#         -- Value 3: non-anginal pain\n",
    "#         -- Value 4: asymptomatic\n",
    "# 10 trestbps: resting blood pressure (in mm Hg on admission to the  # float \n",
    "#         hospital)\n",
    "# 12 chol: serum cholestoral in mg/dl float \n",
    "# 16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "# 19 restecg: resting electrocardiographic results\n",
    "#         -- Value 0: normal\n",
    "#         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n",
    "#                     elevation or depression of > 0.05 mV)\n",
    "#         -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "#                     by Estes' criteria\n",
    "# 32 thalach: maximum heart rate achieved\n",
    "# 38 exang: exercise induced angina (1 = yes; 0 = no)\n",
    "# 40 oldpeak = ST depression induced by exercise relative to rest\n",
    "# 41 slope: the slope of the peak exercise ST segment\n",
    "#         -- Value 1: upsloping\n",
    "#         -- Value 2: flat\n",
    "#         -- Value 3: downsloping\n",
    "# 44 ca: number of major vessels (0-3) colored by flourosopy\n",
    "# 51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "# 58 num: diagnosis of heart disease (angiographic disease status)\n",
    "#         -- Value 0: < 50% diameter narrowing\n",
    "#         -- Value 1: > 50% diameter narrowing\n",
    "#         (in any major vessel: attributes 59 through 68 are vessels)\n",
    "\n",
    "\n",
    "\n",
    "# Define categorical and numerical columns based on the provided description\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'num']\n",
    "numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "# Convert categorical columns to object type\n",
    "for col in categorical_cols:\n",
    "    cleveland[col] = cleveland[col].astype('object')\n",
    "    test[col] = test[col].astype('object')\n",
    "\n",
    "# Ensure numerical columns are numeric (already handled in previous code)\n",
    "for col in numerical_cols:\n",
    "    cleveland[col] = pd.to_numeric(cleveland[col], errors='coerce')\n",
    "    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "# Print the data types of each column to verify the changes (optional)\n",
    "print(cleveland.dtypes)\n",
    "print(test.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Split the cleveland dataframe in a train and a validation set. `\n",
    "\n",
    "The train set must be called train, the the validation set must be called val. The size of the validation set must be 30% of the total size of the cleveland dataframe. Use shuffle=True and stratify=True. Make sure that both train and val are dataframes, and that the columns have the correct names. Reset the indexes of all four the dataframes, using drop=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and validation sets\n",
    "train, val = train_test_split(cleveland, test_size=0.3, random_state=RSEED, shuffle=True, stratify=cleveland['num'])\n",
    "\n",
    "# Reset the index of the DataFrames\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "\n",
    "# Split the data into X and y\n",
    "X_cleveland = train.drop('num', axis=1)\n",
    "y_cleveland = train['num']\n",
    "\n",
    "X_test = val.drop('num', axis=1)\n",
    "y_test = val['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = X_cleveland\n",
    "X_val = X_test\n",
    "y_train = y_cleveland\n",
    "y_val = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs restecg  thalach exang  oldpeak slope  \\\n",
       "0  76.0  0.0  3.0     140.0  197.0  0.0     1.0    116.0   0.0      1.1   2.0   \n",
       "1  47.0  1.0  3.0     108.0  243.0  0.0     0.0    152.0   0.0      0.0   1.0   \n",
       "2  54.0  0.0  3.0     110.0  214.0  0.0     0.0    158.0   0.0      1.6   2.0   \n",
       "3  66.0  0.0  4.0     178.0  228.0  1.0     0.0    165.0   1.0      1.0   2.0   \n",
       "4   NaN  1.0  4.0     140.0  293.0  0.0     2.0    170.0   0.0      1.2   2.0   \n",
       "\n",
       "    ca thal  \n",
       "0  0.0  3.0  \n",
       "1  0.0  3.0  \n",
       "2  0.0  3.0  \n",
       "3  2.0  7.0  \n",
       "4  2.0  7.0  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs restecg  thalach exang  oldpeak slope  \\\n",
       "0  64.0  1.0  3.0     140.0  335.0  0.0     0.0    158.0   0.0      0.0   1.0   \n",
       "1  42.0  1.0  3.0     130.0  180.0  0.0     0.0    150.0   0.0      0.0   1.0   \n",
       "2  34.0  1.0  1.0     118.0  182.0  0.0     2.0    174.0   0.0      0.0   1.0   \n",
       "3  55.0  1.0  2.0     130.0  262.0  0.0     0.0    155.0   0.0      0.0   1.0   \n",
       "4  35.0  1.0  4.0     120.0  198.0  0.0     0.0    130.0   1.0      1.6   2.0   \n",
       "\n",
       "    ca thal  \n",
       "0  0.0  3.0  \n",
       "1  0.0  3.0  \n",
       "2  0.0  3.0  \n",
       "3  0.0  3.0  \n",
       "4  0.0  7.0  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "X_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the classification task easier, transform the target variable into a binary variable.\n",
    "# If the target variable is 0, it should remain 0. If the target variable is different from 0, it should be transformed into 1.\n",
    "\n",
    "\n",
    "y_train = (y_train != 0).astype(int)\n",
    "y_val = (y_val != 0).astype(int)\n",
    "y_test = (y_test != 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_set_from_franco = pd.read_csv('../../../testing_data/train.csv')\\nval_set_from_franco = pd.read_csv('../../../testing_data/val.csv')\\n\\nassert train.equals(train_set_from_franco), 'train set is not correct'\\nassert val.equals(val_set_from_franco), 'validation set is not correct'\\n\""
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "\n",
    "'''\n",
    "train_set_from_franco = pd.read_csv('../../../testing_data/train.csv')\n",
    "val_set_from_franco = pd.read_csv('../../../testing_data/val.csv')\n",
    "\n",
    "assert train.equals(train_set_from_franco), 'train set is not correct'\n",
    "assert val.equals(val_set_from_franco), 'validation set is not correct'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: impute the missing values in the categorical columns. Use a KNNImputer from sklearn for the imputation process. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a subset of the train dataset with only the categorical columns. Call this subset train_cat.\n",
    "# 2. Create a subset of the val dataset with only the categorical columns. Call this subset val_cat.\n",
    "# 3. Create a subset of the test dataset with only the categorical columns. Call this subset test_cat\n",
    "# 4. Impute the three datasets using a KNN imputer with k=5 and weights set to distance\n",
    "# 5. Save the results in train_imputed_knn, val_imputed_knn, and test_imputed_knn.\n",
    "# 6. Make sure to add the column names to the resulting dataframes. DO NOT SKIP THIS STEP.\n",
    "# The new values might have new values that are not in the original dataset.\n",
    "# Approximate them to the nearest value in the original dataset, for each column.\n",
    "# To do so, you can store the original values of each column in a dictionary or a list.\n",
    "# if a new value is equidistant from two original values, choose the largest one.\n",
    "# (Example: if the original values are [1, 3] and the new value is 2, it will become 3)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# 1. & 2. Create subsets with categorical columns\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "train_cat = train[categorical_cols]\n",
    "val_cat = val[categorical_cols]\n",
    "test_cat = test[categorical_cols]\n",
    "\n",
    "# Store original values for each categorical column\n",
    "original_values = {}\n",
    "for col in categorical_cols:\n",
    "    original_values[col] = sorted(train_cat[col].dropna().unique())\n",
    "\n",
    "\n",
    "# 3. Impute the datasets using KNN imputer\n",
    "imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "\n",
    "train_imputed_knn = pd.DataFrame(imputer.fit_transform(train_cat))\n",
    "val_imputed_knn = pd.DataFrame(imputer.transform(val_cat))\n",
    "test_imputed_knn = pd.DataFrame(imputer.transform(test_cat))\n",
    "\n",
    "\n",
    "# Add column names back\n",
    "train_imputed_knn.columns = categorical_cols\n",
    "val_imputed_knn.columns = categorical_cols\n",
    "test_imputed_knn.columns = categorical_cols\n",
    "\n",
    "# Approximate new values to the nearest original value\n",
    "def approximate_to_nearest(value, original_vals):\n",
    "    if pd.isna(value):\n",
    "      return value\n",
    "    \n",
    "    if value in original_vals:\n",
    "        return value\n",
    "    \n",
    "    distances = [abs(value - original_val) for original_val in original_vals]\n",
    "    min_distance = min(distances)\n",
    "    \n",
    "    candidates = [original_vals[i] for i, d in enumerate(distances) if d == min_distance]\n",
    "    return max(candidates)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train_imputed_knn[col] = train_imputed_knn[col].apply(lambda x: approximate_to_nearest(x, original_values[col]))\n",
    "    val_imputed_knn[col] = val_imputed_knn[col].apply(lambda x: approximate_to_nearest(x, original_values[col]))\n",
    "    test_imputed_knn[col] = test_imputed_knn[col].apply(lambda x: approximate_to_nearest(x, original_values[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_imp_knn_franco = pd.read_csv('../../../testing_data/train_imp_knn.csv')\\nval_imp_knn_franco = pd.read_csv('../../../testing_data/val_imp_knn.csv')\\ntest_imp_knn_franco = pd.read_csv('../../../testing_data/test_imp_knn.csv')\\n\\nassert train_imputed_knn.equals(train_imp_knn_franco), 'train imputed knn is not correct'\\nassert val_imputed_knn.equals(val_imp_knn_franco), 'val imputed knn is not correct'\\nassert test_imputed_knn.equals(test_imp_knn_franco), 'test imputed knn is not correct'\\n\""
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "'''\n",
    "train_imp_knn_franco = pd.read_csv('../../../testing_data/train_imp_knn.csv')\n",
    "val_imp_knn_franco = pd.read_csv('../../../testing_data/val_imp_knn.csv')\n",
    "test_imp_knn_franco = pd.read_csv('../../../testing_data/test_imp_knn.csv')\n",
    "\n",
    "assert train_imputed_knn.equals(train_imp_knn_franco), 'train imputed knn is not correct'\n",
    "assert val_imputed_knn.equals(val_imp_knn_franco), 'val imputed knn is not correct'\n",
    "assert test_imputed_knn.equals(test_imp_knn_franco), 'test imputed knn is not correct'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4.* Imputing numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: impute the missing values in the numerical columns. Use a Lasso Regression from sklearn for the imputation process. `\n",
    "If more than one column contains missing values, proceed in increasing order: the lowest number of missing values first, then the second lowest, then the third ...\n",
    "\n",
    "Exclude the columns with missing values when fitting your regressor: only train on columns without missing values. After a column has been imputed, it can be used to fit the regressor in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_base.py:598: UserWarning: Skipping features without any observed values: ['age']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2, 3), indices imply (2, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[364], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Impute missing values\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m train_num_missing\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     67\u001b[0m     train_num_imputed_lasso \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m---> 68\u001b[0m         [train_num_imputed_lasso, \u001b[43mimpute_with_lasso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_num_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlasso_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     )\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m val_num_missing\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     72\u001b[0m     val_num_imputed_lasso \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[0;32m     73\u001b[0m         [val_num_imputed_lasso, impute_with_lasso(val_num_missing, lasso_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchol\u001b[39m\u001b[38;5;124m'\u001b[39m)], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[364], line 32\u001b[0m, in \u001b[0;36mimpute_with_lasso\u001b[1;34m(df_missing, lasso_model, target_col)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Impute missing values in X_missing before prediction using SimpleImputer\u001b[39;00m\n\u001b[0;32m     31\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m X_missing_imputed \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_missing\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_missing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Debugging step: Check the shape of X_missing_imputed\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_missing_imputed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_missing_imputed\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (2, 3), indices imply (2, 4)"
     ]
    }
   ],
   "source": [
    "# 1. Create a subset of the train dataset with only the numerical columns. \n",
    "# 2. Create a subset of the val dataset with only the numerical columns. Call this subset val_num.\n",
    "# 3. Create a subset of the test dataset with only the numerical columns. Call this subset test_num.\n",
    "# 4a. Create a subset of train_num containing the rows with missing values. Call this subset train_num_missing.\n",
    "# 4b. Create a subset of train_num containing the rows without missing values. Call this subset train_num_not_missing.\n",
    "# 5a. Create a subset of val_num containing the rows with missing values. Call this subset val_num_missing.\n",
    "# 5b. Create a subset of val_num containing the rows without missing values. Call this subset val_num_not_missing.\n",
    "# 6a. Create a subset of test_num containing the rows with missing values. Call this subset test_num_missing.\n",
    "# 6b. Create a subset of test_num containing the rows without missing values. Call this subset test_num_not_missing.\n",
    "# 7. Using a Lasso regression, impute the missing values in train_num_missing, val_num_missing, and test_num_missing.\n",
    "# On what should the Lasso regression be trained?\n",
    "# 8. Repeat steps 1-7 until all the missing values are imputed.\n",
    "# 9. Save the results in train_num_imputed_lasso, val_num_imputed_lasso, and test_num_imputed_lasso.\n",
    "# 10. Concatenate the imputed subsets with the subsets that did not contain missing values.\n",
    "# 11. Save the resulting datasets in train_imputed_lasso, val_imputed_lasso, and test_imputed_lasso.\n",
    "# IMPORTANT: The order of the rows should be the same as in the original datasets.\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "train_num = train[numerical_cols] # 1. Create a subset of the train dataset with only the numerical columns.Call this subset train_num.\n",
    "val_num = val[numerical_cols]\n",
    "test_num = test[numerical_cols]\n",
    "\n",
    "# 4. Create subsets of train_num with and without missing values\n",
    "train_num_missing = train_num[train_num.isnull().any(axis=1)]\n",
    "train_num_not_missing = train_num.dropna()\n",
    "\n",
    "# 5. Create subsets of val_num with and without missing values\n",
    "val_num_missing = val_num[val_num.isnull().any(axis=1)]\n",
    "val_num_not_missing = val_num.dropna()\n",
    "\n",
    "# 6. Create subsets of test_num with and without missing values\n",
    "test_num_missing = test_num[test_num.isnull().any(axis=1)]\n",
    "test_num_not_missing = test_num.dropna()\n",
    "# 7. Impute missing values using Lasso regression\n",
    "# Train Lasso on the subset without missing values\n",
    "\n",
    "# Before training Lasso, impute missing values in X_train_lasso using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')  # You can change the strategy if needed\n",
    "X_train_lasso = train_num_not_missing.drop(columns=['chol'])  # Example: Exclude 'chol' if it has missing values in the non-missing subset\n",
    "y_train_lasso = train_num_not_missing['chol']  # Example: Predict 'chol'\n",
    "X_train_lasso_imputed = pd.DataFrame(imputer.fit_transform(X_train_lasso), columns=X_train_lasso.columns, index=X_train_lasso.index)\n",
    "\n",
    "lasso_model = Lasso(alpha=0.1)  # You can tune alpha\n",
    "lasso_model.fit(X_train_lasso_imputed, y_train_lasso)  # Fit Lasso on imputed data\n",
    "\n",
    "\n",
    "\n",
    "# Function to impute missing values using a Lasso model\n",
    "def impute_with_lasso(df_missing, lasso_model, target_col):\n",
    "    df_imputed = df_missing.copy()\n",
    "    X_missing = df_missing.drop(columns=[target_col])\n",
    "    \n",
    "    # Impute missing values in X_missing before prediction using SimpleImputer\n",
    "    X_missing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_imp_lasso_franco = pd.read_csv('../../../testing_data/train_imp_lasso.csv')\\nval_imp_lasso_franco = pd.read_csv('../../../testing_data/val_imp_lasso.csv')\\ntest_imp_lasso_franco = pd.read_csv('../../../testing_data/test_imp_lasso.csv')\\n\\nassert train_imputed_lasso.equals(train_imp_lasso_franco), 'train imputed lasso is not correct'\\nassert val_imputed_lasso.equals(val_imp_lasso_franco), 'val imputed lasso is not correct'\\nassert test_imputed_lasso.equals(test_imp_lasso_franco), 'test imputed lasso is not correct'\\n\""
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "'''\n",
    "train_imp_lasso_franco = pd.read_csv('../../../testing_data/train_imp_lasso.csv')\n",
    "val_imp_lasso_franco = pd.read_csv('../../../testing_data/val_imp_lasso.csv')\n",
    "test_imp_lasso_franco = pd.read_csv('../../../testing_data/test_imp_lasso.csv')\n",
    "\n",
    "assert train_imputed_lasso.equals(train_imp_lasso_franco), 'train imputed lasso is not correct'\n",
    "assert val_imputed_lasso.equals(val_imp_lasso_franco), 'val imputed lasso is not correct'\n",
    "assert test_imputed_lasso.equals(test_imp_lasso_franco), 'test imputed lasso is not correct'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *5.* Classification with Decision Tree, using a single split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the train_imputed_knn and train_imputed_lasso datasets. Call the resulting dataset X_train_imputed.\n",
    "# Merge the val_imputed_knn and val_imputed_lasso datasets. Call the resulting dataset X_val_imputed.\n",
    "# Merge the test_imputed_knn and test_imputed_lasso datasets. Call the resulting dataset X_test_imputed.\n",
    "\n",
    "X_train_imputed = pd.concat([train_imputed_knn, train_imputed_lasso], axis=1)\n",
    "X_val_imputed = pd.concat([val_imputed_knn, val_imputed_lasso], axis=1)\n",
    "X_test_imputed = pd.concat([test_imputed_knn, test_imputed_lasso], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Train a set of Decision Trees, using different hyperparameters. Use the best performing Decision Tree to predict the class for the test set. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 2}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 5}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 2}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 5}, F1 Score: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 10}, F1 Score: 1.0\n",
      "Time elapsed to run the hyperparameter tuning with a single split:  0.061141252517700195\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a dictionary to contain the hyperparameters. The dictionary should contain the following:\n",
    "# - criterion: 'gini' and 'entropy'\n",
    "# - max_depth: 3, 5, and 7\n",
    "# - min_samples_split: 2, 5, and 10\n",
    "# 2. Create a dictionary called performance to store the hyperparameter combinations and the corresponding performance of the model.\n",
    "# 3. Create a ParameterGrid object with the hyperparameters from the dictionary.\n",
    "# 4. Create a for loop to iterate over the combinations of hyperparameters.\n",
    "# 5. In each iteration\n",
    "# - Create a DecisionTreeClassifier with the hyperparameters for that iteration.\n",
    "# - Fit the model.\n",
    "# - Predict the target variable for the validation set.\n",
    "# - Calculate the F1 score of the model.\n",
    "# - Add the hyperparameters and the F1 score to the performance dictionary.\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "\n",
    "# 1. Create a dictionary to contain the hyperparameters.\n",
    "hyperparameters = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# 2. Create a dictionary called performance to store the hyperparameter combinations and the corresponding performance of the model.\n",
    "performance = {}\n",
    "\n",
    "# 3. Create a ParameterGrid object with the hyperparameters from the dictionary.\n",
    "param_grid = ParameterGrid(hyperparameters)\n",
    "\n",
    "\n",
    "start = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "# 4. Create a for loop to iterate over the combinations of hyperparameters.\n",
    "for params in param_grid:\n",
    "    # 5. In each iteration:\n",
    "    # - Create a DecisionTreeClassifier with the hyperparameters for that iteration.\n",
    "    model = DecisionTreeClassifier(**params, random_state=RSEED)\n",
    "    \n",
    "    # - Fit the model.\n",
    "    model.fit(X_train_imputed, y_train)\n",
    "    \n",
    "    # - Predict the target variable for the validation set.\n",
    "    y_pred = model.predict(X_val_imputed)\n",
    "    \n",
    "    # - Calculate the F1 score of the model.\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    # - Add the hyperparameters and the F1 score to the performance dictionary.\n",
    "    performance[str(params)] = f1\n",
    "\n",
    "end = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "# Print or further process the performance dictionary\n",
    "for params, f1 in performance.items():\n",
    "    print(f\"Hyperparameters: {params}, F1 Score: {f1}\")\n",
    "print('Time elapsed to run the hyperparameter tuning with a single split: ', end - start) # DO NOT CHANGE/DELETE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\""
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the hyperparameters that resulted in the best F1 score\n",
    "best_hyperparameters = max(performance, key=performance.get)\n",
    "\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train and validation datasets.\n",
    "X = pd.concat([X_train_imputed, X_val_imputed], axis=0).reset_index(drop=True)\n",
    "y = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Create a DecisionTreeClassifier with the best hyperparameters.\n",
    "# Find the best hyperparameters from the performance dictionary\n",
    "best_params_str = max(performance, key=performance.get)\n",
    "best_params = eval(best_params_str)  # Convert the string back to a dictionary\n",
    "\n",
    "# Create the model with the best parameters\n",
    "best_model = DecisionTreeClassifier(**best_params, random_state=RSEED)\n",
    "\n",
    "# Fit the model on the combined training and validation sets\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Predict the target variable for the test dataset.\n",
    "y_pred_test = best_model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate the F1 score of the model on the test dataset.\n",
    "# Convert test['num'] to a numeric type before calculating the F1 score\n",
    "f1_test_single_split = f1_score(test['num'].astype(int), y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9661016949152542)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test_single_split # DO NOT DELETE/CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *6.* Classification with Decision Tree using Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Train a cross-validation object, then train a decision tree using cross-validation and different hyperparameters. Use the best performing Decision Tree to predict the class for the test set. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 2}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 5}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 2}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 5}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n",
      "Hyperparameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 10}, F1 Scores: [np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0), np.float64(1.0)], Average F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the same hyperparameters from the previous task.\n",
    "# 2. Create a StratifiedKFold object with 5 splits, use shuffle=True.\n",
    "# 3. Create a dictionary called performance_CV to store the hyperparameter combinations and the corresponding performance of the model.\n",
    "# 3. Create a ParameterGrid object with the usual hyperparameters.\n",
    "# 4. Create a for loop to iterate over the folds of the StratifiedKFold.\n",
    "# 5. For each fold, create a for loop to iterate over the combinations of hyperparameters.\n",
    "# 6. In each iteration\n",
    "# - Create a DecisionTreeClassifier with the hyperparameters for that iteration.\n",
    "# - Fit the model.\n",
    "# - Predict the target variable for the validation fold.\n",
    "# - Calculate the F1 score of the model.\n",
    "# - Add the hyperparameters and the F1 score to the performance dictionary. Each hyperparameter combination may have multiple F1 scores.\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Assuming RSEED is defined elsewhere in your code\n",
    "RSEED = 42  # Replace with your actual RSEED value if different\n",
    "\n",
    "# ... (your existing code) ...\n",
    "\n",
    "# 2. Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RSEED)\n",
    "\n",
    "# 3. Create a dictionary to store performance\n",
    "performance_CV = {}\n",
    "\n",
    "# 4 & 5. Iterate over folds and hyperparameters\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X_train_imputed, y_train)):\n",
    "    X_train_fold, X_val_fold = X_train_imputed.iloc[train_index], X_train_imputed.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    for params in param_grid:\n",
    "        model = DecisionTreeClassifier(**params, random_state=RSEED)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        f1 = f1_score(y_val_fold, y_pred)\n",
    "\n",
    "        # Store results, handling potential key collisions\n",
    "        key = str(params)\n",
    "        if key not in performance_CV:\n",
    "            performance_CV[key] = []\n",
    "        performance_CV[key].append(f1)\n",
    "\n",
    "# Print or further process the performance_CV dictionary\n",
    "for params, f1_scores in performance_CV.items():\n",
    "    print(f\"Hyperparameters: {params}, F1 Scores: {f1_scores}, Average F1: {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\""
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the best performing hyperparameters, which are the ones with the highest average F1 score\n",
    "# Calculate the average F1 score for each hyperparameter combination\n",
    "average_f1_scores = {params: np.mean(scores) for params, scores in performance_CV.items()}\n",
    "\n",
    "# Find the hyperparameters with the highest average F1 score\n",
    "best_hyperparameters_CV = max(average_f1_scores, key=average_f1_scores.get)\n",
    "\n",
    "best_hyperparameters_CV # DO NOT DELETE/CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(best_hyperparameters_CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [91, 122]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[344], line 23\u001b[0m\n\u001b[0;32m     17\u001b[0m y_pred_test_CV \u001b[38;5;241m=\u001b[39m final_tree\u001b[38;5;241m.\u001b[39mpredict(X_test_imputed)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate the F1 score of the model on the test dataset. Call the variable f1_test_CV.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Write your code here\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m f1_test_CV \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_test_CV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m f1_test_CV \u001b[38;5;66;03m# change this\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1293\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1114\u001b[0m     {\n\u001b[0;32m   1115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1141\u001b[0m ):\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1485\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1306\u001b[0m     {\n\u001b[0;32m   1307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1334\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1335\u001b[0m ):\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03m    np.float64(0.12...)\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1485\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1789\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m \n\u001b[0;32m   1628\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1789\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1792\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1561\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1561\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [91, 122]"
     ]
    }
   ],
   "source": [
    "# Create a DecisionTreeClassifier with the best hyperparameters.\n",
    "# Fit the model on the X and y datasets.\n",
    "# Call the fitted model final_tree.\n",
    "\n",
    "import ast\n",
    "\n",
    "best_hyperparameters_CV = ast.literal_eval(\"{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\")\n",
    "\n",
    "final_tree = DecisionTreeClassifier(**best_hyperparameters_CV, random_state=RSEED)\n",
    "\n",
    "final_tree.fit(X, y)\n",
    "\n",
    "# Predict the target variable for the test dataset.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "y_pred_test_CV = final_tree.predict(X_test_imputed)\n",
    "\n",
    "# Calculate the F1 score of the model on the test dataset. Call the variable f1_test_CV.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "f1_test_CV = f1_score(val, y_pred_test_CV)\n",
    "\n",
    "f1_test_CV # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test_CV # DO NOT DELETE/CHANGE THIS LINE \n",
    " \n",
    "  \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *7.* Interpretation of the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Look at the times elapsed to train the Decision Tree using the single split and the CV strategies. Is there a difference? Explain the difference or the lack of difference in 50 words or less. `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your explanation here. Delete this text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Plot final_tree, and explain which feature or combination of features is the most relevant for that model, in 50 words or less. `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find instructions on how to plot a decision tree at [this link](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot your tree here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your explanation here. Delete this text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
